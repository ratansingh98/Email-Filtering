{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv',sep='\\t',header=None)\n",
    "messages = pd.DataFrame(list(zip(data[0].values,data[1].values)),columns=['Class','Message'])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Message\n",
      "Class         \n",
      "ham       4825\n",
      "spam       747\n",
      "\n",
      "Total Message 5572\n"
     ]
    }
   ],
   "source": [
    "print(messages.groupby('Class').count())\n",
    "print(\"\\nTotal Message\",len(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [go, until, jurong, point, crazy, available, o...\n",
      "1                       [ok, lar, joking, wif, u, oni]\n",
      "2    [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
      "3    [u, dun, say, so, early, hor, u, c, already, t...\n",
      "4    [nah, i, do, n't, think, he, goes, to, usf, he...\n",
      "Name: Message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Split Mesaage to words\n",
    "SplitIntoWords = lambda message: TextBlob(message.lower()).words\n",
    "print(messages.Message.head().apply(SplitIntoWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert words to base form\n",
    "WordsIntoBaseForm = lambda message: [word.lemma for word in SplitIntoWords(message)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each messafe into a vector\n",
    "trainingVector = CountVectorizer(analyzer=WordsIntoBaseForm,stop_words = 'english').fit(messages['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 88)\t1\n",
      "  (0, 359)\t1\n",
      "  (0, 1914)\t1\n",
      "  (0, 1947)\t1\n",
      "  (0, 2208)\t1\n",
      "  (0, 2240)\t1\n",
      "  (0, 3039)\t1\n",
      "  (0, 3382)\t1\n",
      "  (0, 3433)\t2\n",
      "  (0, 3778)\t1\n",
      "  (0, 4645)\t1\n",
      "  (0, 5182)\t3\n",
      "  (0, 5215)\t1\n",
      "  (0, 5222)\t1\n",
      "  (0, 5643)\t1\n",
      "  (0, 5690)\t1\n",
      "  (0, 6301)\t1\n",
      "  (0, 7673)\t2\n",
      "  (0, 7801)\t2\n",
      "  (0, 8002)\t1\n",
      "  (0, 8099)\t2\n",
      "  (0, 8495)\t1\n",
      "  (0, 8747)\t1\n"
     ]
    }
   ],
   "source": [
    "message10 = trainingVector.transform([messages['Message'][9]])\n",
    "print(message10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n"
     ]
    }
   ],
   "source": [
    "# Print message #10 for comparison\n",
    "print(messages['Message'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First word that appears twice: free\n",
      "Word that appears three times: mobile\n"
     ]
    }
   ],
   "source": [
    "# Identify repeated words\n",
    "print ('First word that appears twice:',trainingVector.get_feature_names()[3433])\n",
    "print ('Word that appears three times:',trainingVector.get_feature_names()[5182])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words for whole training data\n",
    "messagesBagOfWords = trainingVector.transform(messages[\"Message\"])\n",
    "# Weight of words int the entire training data\n",
    "TfidfTransformer = TfidfTransformer()\n",
    "messagesTfidf = TfidfTransformer.fit_transform(messagesBagOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x8859 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"england\"]\n",
    "trainingVector.transform(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messagesTfidf,messages['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 8859)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.89231873654\n"
     ]
    }
   ],
   "source": [
    "# Using GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "spamDetector = GaussianNB().fit(X_train.toarray(),y_train)\n",
    "y_pred = spamDetector.predict(X_test.toarray())\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "classifiers.append(['GaussianNB',accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.953338119167\n"
     ]
    }
   ],
   "source": [
    "# Using MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "spamDetector = MultinomialNB().fit(X_train,y_train)\n",
    "y_pred = spamDetector.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "classifiers.append(['MultinomialNB',accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.981335247667\n"
     ]
    }
   ],
   "source": [
    "# Using BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "spamDetector = BernoulliNB().fit(X_train,y_train)\n",
    "y_pred = spamDetector.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "classifiers.append(['BernoulliNB',accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.969849246231\n"
     ]
    }
   ],
   "source": [
    "# Using Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "spamDetector = RandomForestClassifier().fit(X_train,y_train)\n",
    "y_pred = spamDetector.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "classifiers.append(['RandomForestClassifier',accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.870782483848\n"
     ]
    }
   ],
   "source": [
    "# Using SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "spamDetector = SVC().fit(X_train,y_train)\n",
    "y_pred = spamDetector.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "classifiers.append(['SVC',accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.981335247667\n"
     ]
    }
   ],
   "source": [
    "# Using LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "spamDetector = LinearSVC().fit(X_train,y_train)\n",
    "y_pred = spamDetector.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "classifiers.append(['LinearSVC',accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.982053122757\n"
     ]
    }
   ],
   "source": [
    "# Using SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "spamDetector = SGDClassifier().fit(X_train,y_train)\n",
    "y_pred = spamDetector.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "classifiers.append(['SGDClassifier',accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['GaussianNB', 0.89231873653984206],\n",
       " ['MultinomialNB', 0.95333811916726485],\n",
       " ['BernoulliNB', 0.98133524766690594],\n",
       " ['RandomForestClassifier', 0.96984924623115576],\n",
       " ['SVC', 0.87078248384781043],\n",
       " ['LinearSVC', 0.98133524766690594],\n",
       " ['SGDClassifier', 0.98205312275664036]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1168d0438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objects = [i[0] for i in classifiers]\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [(round(i[1],4)*100) for i in classifiers]\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.8)\n",
    "for i, v in enumerate(performance):\n",
    "    plt.text(v-15 , i-0.1 , str(v)+\"%\", color='white',fontweight='bold')\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Accuaracy')\n",
    "plt.title('Performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.983488872936\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Dump the model\n",
    "spamDetector = SGDClassifier().fit(X_train,y_train)\n",
    "y_pred = spamDetector.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "print(\"Accuracy is \",accuracy)\n",
    "pickle.dump(spamDetector,open('model.sav','wb'))\n",
    "\n",
    "import dill\n",
    "# Dump the trainingVector\n",
    "with open(\"trainingVector\", \"wb\") as dill_file:\n",
    "    dill.dump(trainingVector, dill_file)\n",
    "#pickle.dump(trainingVector,open('trainingVector.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['England v Macedonia - dont miss the goals/team news. Txt ENGLAND to 99999']\n",
    "# Result\n",
    "checkResult = spamDetector.predict(trainingVector.transform(example))\n",
    "print ('The message [',example[0],'] has been classified as', checkResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
